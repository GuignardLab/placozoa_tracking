# Monday 31/10/2022 

## Drift correction:

The idea is to correct for drif using the algae.

Workflow: 
- Segment the algae plane per plane
- Map the objects between time t and t +1 
- Compute and correct for the translation 

## Segment the algae plane per plane

To do so, I remove the organism from the image (maybe we don't need to )

![[organism_removal.png]]

# Tuesay 01/11/2022

Idea for the presentation/report: make a diagram of the pipeline and present it in order:

- Preprocess:
	- Contrast enhancement
	- algae removal
	- drift correction
- Segmentation:
	- Different techniques
	- difference between them
	- performance metrics
	- results 
- Quantification:
	- area over time
	- perimeter
	- trajectory
	- MSD
	- behavioural patterns
	- ...
- Implementation
	- plugin
	- GUI : Napari
	- use


Present it as a vertical diagram. And write the report as a description of the different modules.

# Wednesday 02/11/2022:

Meeting with l√©o: 

- make the drift correction as part of the analysis module (only to compute trajectory)
- Try to compute the drift by removing the largest component (no need to be precise)
- Otherwise try to correct the drift using trajectory gaps.
- To have a visual representation of the drift increase the size of the image as the camera moves to create a big image with the "real movment of the oarganism"
- segment the algae using a sliding window to avoid this drift. 

## Segmentation: 

I managed to connect to the LIS cluster and lunch a YAPIC training. With the following parameters:

```python
from yapic.session import Session

img_path = str(dataset_path/"input_test")+'/*.tif'
label_path = str(dataset_path/"target_test")+'/*.tif'

model_size_xy = (1,572, 572)

t = Session()
print(t)
t.load_training_data(img_path, label_path)

t.make_model('unet_2d', model_size_xy)

t.define_validation_data(0.2) # 80% training data, 20% validation data

t.train(max_epochs=5,
        steps_per_epoch=5,
        log_filename='../models/log.csv')

t.model.save('../models/my_model.h5')
```

Note: I have an issue with the non_modified images that are not "memory mappable" and thus the training is on on enhanced images... I don't know what is happening...

Idea:  taking an already trained stardist network to use for the side project I have with the MCF tracking ... 

The network learned something: 

![[Pasted image 20221102152630.png]]


## Drift correction: 

![[animation_drift.gif]]

I defnied a function to compute the position of the algea plane per plane: 

 Function to get the algae per plane:
    workflow:
        - remove the organism from the image
        - segment
        - remove largest component (also the organism but it also removes the algae that are under the organism)
        - return the segmented image 
    Inputs:
        - raw image
        - plane to segment
        - corresponding mask of the organism

Now the next step is to register the objects between planes and then compute the distance between them i.e. the dirft.

Maybe also apply a filter somewhere for the size of the segmented object to only keep "algae objects". 

# Thursday 03/11/2022

## Drift correction

To compute the drift I need to assign each point at time t to the same point at time t+1 (assuming there is only one movement between 2 frames: verified). To do so I used 2 different approaches:

- The [linear sum assignment](http://www.assignmentproblems.com/doc/LSAPIntroduction.pdf)
- The [min weight full bipartite matching](https://sites.math.washington.edu/~raymonda/assignment.pdf)

### Function to compute the drift

Function to compute the drift between 2 time points.
Workflow:
- Create the distance matrix i.e. the "distance" between every point
- perform linear sum assignment on this matrix
- extract the best assignment and compute the 'optimal distance' between the assigned points  
Input: 
- The 2 dataframes containing the position of all the algae for the 2 planes
- the method to assign the objects default: linear

### Few observations:
- The two methods yield similar results
- The average drift is the same as when I computed between 3 relevant points (even if the sd is bigger) so it averages out
- the assignment is only keeping the lowest number of point (dimention of the matrix) so some points are not assigned and thus the assignment is not perfect hence a big sd...
- With this method I only compute the absolute value of the drift (because I'm taking the eucledian distance)
- If I want the direction of the distance I would need another measure ...

### Function to compute the global drift of the image

Workflow:
- Loop over planes
- compute the labels for the 2 images
- call the drift computation function to extract the mean drift between plane t and t+1
- append the mean drift of all points to a list
Inputs:
- the mask_image of all the algae for each time point
- the method to map the points between 2 time points

### To verify this result I used ImageJ: 
- Compute the centroid of an algae at time t
- Compute the centroid of the same algae at time t+1
- Make the difference and call it drift

Result of my function for a lateral drift: 
13.079362928522809, 44.1259986257513, 41.93729814906573, 50.73581669610456, 42.88430606688589, 0.619365196127853

Whereas I find more or less 10 pixels when using imageJ. I tried to take the median to avoid having outliers but it didn't really improve the result. 

Things to do:
- Find another way to compute the distance
- Find a way to get the direction of the movement
- Try to correct a trajectory with the drift

# 04/11/2022

Worflow for drift correction for now:

**1. Segment the algea plane per plane using alg function:**
	- Inputs:
		- The raw image
		- The corresponding mask
	- output:
		- the segmented algae plane per plane

**2. Compute the drift using the global_drift function:**
	- Inputs:
		- The output of the alg function
		- the method to compute the assignement (default is linear assignment)
	- Output:
		- list of drift for 2 consecutive planes

### Preprocessing the image updated version:

#### Workflow: 
1. Segment the algae:
	1. Alg function : (raw image, masked image)
2. Correct the image:
	1. correct function: (algae mask, raw image)
3. Contrast enhancement:
	1. stretching function: (raw image)

I did this operation on an image of 365 planes and it took 10 minutes... Knowing that there is no drift and 10 times less planes.

To compare I used the tricho_8 movie and ran the segmentation pipeline and compared the different metrics. I also used the manual contrast movie to compare.

![[placozoa_tracking/data/results/figures/compare/full_pipeline/all_features_contrast_filled_both.png]]

The results don't look very promissing but we might see a difference in the wound features...

![[all_features_wound.png]]
We see that the preprocessing was able to recapture the manual contrast tendency. However it seems that the time needed to arrive at this result might not be optimal... 

