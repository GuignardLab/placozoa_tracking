# Monday 14/11/2022

Things to do this week:
- Improve the efficiency of the preprocessing pipeline
	- Run a sliding window for the segmentation of the algae instead of doing it plane per plane
- Run it on a longer movie ?
- Try it on different movies
- Define new quantifications
- Retry the NN segmentation
	- Using linux virtual machine

For now the pipeline looks like: 

![[Placozoa tracking.png]]

# Test of the pipeline on a new movie

I tried the full preprocessing pipeline and the drift on a new image (named new_image_1):

I chose to use plane 88 to 101 to have a faster computation time and I chose this time period because there is camera movement.

## Workflow

- Segment the image using Chan vese to have a first mask (with contrast stretching)
- Ran the preprocessing pipeline to have the algae mask
- Ran the drift pipeline to get the drift

## Drift module

The drift module outputs something like:
![[Pasted image 20221114171117.png]]

If you look at the image, the drift captured the first drift in the image (between 88 and 90) but got a lot of unwanted drift. This is due to the quality of the algae mask that is not stable in time an thus creates a wring drift (between 2 planes there are completely new objects  and thus increased distance).

## Segmenting the preprocessed movie

![[full_pipeline.png]]
We don't really see a difference between the processed and the unprocessed. This is maybe due to the fact that there are not a lot of algae that are detectd in the preprocessing and thus in relaity not a lot of correction made to the image.


Maybe if the algae detection was implemented using Otsu method it would yield a better result as they (the algae) are very separated from the background as they are black ... 

## Drift module: Otsu

My intuition was that the segmentation was going to better and thus more algea. If more algae were detected then the matching would be more precise and thus the drift more accurate.

On the same movie the drift module yielded this:

![[Pasted image 20221114175435.png]]


The only real drif in the movie is between frame 89 and 93 (by eye when looking at the video). We see that the module was able to capture this drift. However there seem to be another drift detected between frames 98 and 99 and 100 to 101. To avoid this maybe we can see a threshold:

To be called a "real drift" there must be movement > $x$ pixels for at least $n$ interval. We nned to find a rule to decide on $x$ and $n$

From the previous result we could say that the drift must be at least 10 pixels for more than 4 consicutive frames...

## Sementing the preprocessed movie

Same process as before. Segmentation before (1st try to remove the algae) and after the preprocessing

![[full_pipeline_otsu.png]]

It is a bit better than the previous segmentation as we see a bit more details onthe organism. The most important thing is that it's not worse then before . 

Conclusions:
- we will keep the ostu method of segmentation to remove the algae and compute the drift. But the later segmentation can still be chosen

# Tuesday 15/11/2022 

One thing I realized is that it might be best to stretch the contrast in the begining of the pipeline to increase the contrast and thus segment better the algae.

I decided to segment the full wound movie (with multiple drift) and run the drift pipeline and see the results. I ran the preprocessing pipeline (otsu method) and the drift module.

Another thing I realized was that using the median drift of every poin in the image rather than the mean was better because we have enough point that the median is accurate and not biased by outlier. 

Another thing that conforted me was when looking at the distribution of the drift there was no clear cutoff when I applied the mean whereas it was more clear when I applied the median:

![[drift_distrib.png]]
The distribution on the right is a lot more narrow. 

Hence I followed the analysis with the median. Then I implemented a selection criteria to determine what makes a "real drift" as mentioned yesterday:
- The drift should span for at least 5 frames (from the observation of the video)
- The drift should be more than 5 pixels (from the distribution)

Another way I checked that my assumption was correct was by looking at the scatter plot of the drift:

![[drift_criteria.png]]

If plotted all the drift points against their drift and colored by the criterie I chose ( drift >5) . We see that we have clear regions: right before plane 800 and before plane 1000. These regions have more than 5 points hence the criteria. 

When correlating this plot with the actual movei we see that it matches the moment when the camera moves. 

Zoomed it yields:
![[drift_criteria_zoomed.png]]


## Code review: publish a code

See the tutorial on [RealPython](https://realpython.com/pypi-publish-python-package/#prepare-your-package-for-publication)

See also Cookiecutter for an help on the strcture building of the package.

## Computing an error on the drift

To do so I will use ImageJ to manually compute a drift in the time periods the module detected and then I will compare with the output of the module. 

I took the same point on the raw image and computed it's x and y coordinate. Then compare it to the median drift. 

![[drift_error_scatter.png]]

We see that the 2 look similar. I want to see 2 things: 
- The distribution of the drift from the program (automatic) seems more scattered
- I want to test if the means of the 2 distributions are significantly different

![[drift_error_hist.png]]

![[drift_error_kde.png]]

# Wednseday 16/11/2022

## Meeting with LÃ©o

au lieu de la distance recuperer la difference en x et y avec le best pairing 

creer un canva 
placer l'image dans le canva
calculer un point 0,0 et un point maxX maxY
calculer 0,0 + translation et maxX maxY + translation
min 0,0 et maxX maxY donnent la taille du canva 

calculer le cumulative drift
replacer l'image sur la big canva


plot l'appareillement 
regarder ou l'erreur est la plus grande et comprendre pourquoi

## Looking where the drift pipeline messed up and why 

$$Error = |Real\,distance - Computed\, distance|$$
I retrieved the mathing of the paiting algorithm and plotted the labeled objects colored by this matching (note that the color are not the same because not all the objects are matched ...)

![[drift_error_visual.png]]
If you look at the pink object on the bottom left of the left image you see that it's not well matched in the next plane. There are other points like that hence the median is biased by them hence the error in the end. 

## Looking at the distribution of the error

![[distribution_error.png]]

I wanted to go deeper in the distribution of the error to know where the program failed. Above is plotted the time frames where the error is maximum (30). But we see that the distribution as 2 bumps: at 10 pixels and 30. There are 2 cases where he program fails.

This might be due to the fact that in those frames there aren't many objects and thus a couple of missmatched objects create a strong bias in the final drift.

## Cummulated drift amplitude 

![[cumulated_drift.png]]

I plotted the cummulated drift and the corresponding cummulated error. We see that the cummulated error reaches a quite high percentage of the total distance which is not ideal (30% of error).


## Looking at x and y drift separately

Then I wanted to look at the movement in X or in Y (the direction) for that instead of computing the eucledian distance in the best pairing I computed the difference in x or in y. The direction is given by the sign of this difference.

![[drift_xy.png]]

We see on the left that the 2 drift don't overlap (which is expected as the camera only move in 1D).  When looking at the direction (right) we can see that the camera went down then right (not sure) we can confirm this visually on the video. 

# Thursday 17/11/2022

## Drift visualization

The goal is to have a video witht a bigger image and place each frame at the correct position in this big image depending on their drift.

For that I need 3 things:
- The drift in x and y at each frame and decide which direction is the drift (and its orientation)
- The canva to "paint". Which corresponds to the maximum size of the observed region by the microscope
- A way to place each frame at its corresponding location

A result of this step can be found in :

```
../data/drift_visual.tif
```


# Friday 18/11/2022

## Adjusting the canva size

Finishing the drift movie. On thursday I had issues creating the canva accordingly to the full size of the moive. I fixed it and it works now. The results is still in :

```shell
../data/drift_visual.tif
```

## Computing the error on the rescaling

The error on the rescaling could be from the rescaling itself or the drift measurement. To compute it I mI measured 2 things:

- The first is the position of an algae present in the whole movie on the rescaled image (which should be constant)
- The position of algae defore and after the drift by hand to measure the error on the drift computation.

### Trajectory and x,y distribution of an algae present in the whole rescaled movie

![[error_on_full_movie.png]]

We see that the trajectory moves which indicates an error. We can also compute the distance between this point at time t and t+1 which should be 0.

![[local_cumulated_error.png]]

Computing the cumulative erro we see that we arrive at around 300 pixels in difference from the actual 'real' position and the position in the rescaled movie. 

To make sure this error doesn't come from the rescaling itself I computed by hand the drift in the raw data for each drifting frames and plotted the difference between the computed drift and the actual drift.

### Error in the drift measurement

![[drift_measurement_error.png]]

We see that this error is big and now to see if it's the entirety of the error computed in the rescaling I plot the cumulative error:

![[cummulated_error.png]]

We see that the 2 superpose which means that the error comes from the drift computation. To avoid that we can maybe set a threshold of "possible disances" when we compute the distance matrix to avoid miss assignment...

